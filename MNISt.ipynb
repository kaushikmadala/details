{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python2",
      "display_name": "Python 2"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kaushikmadala/details/blob/master/MNISt.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VO0d4FK40e52",
        "colab_type": "code",
        "outputId": "a2b6f625-5fdb-4755-c951-20a44da2fbc8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Split the data\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.15, shuffle= True)\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, kernel_size=(3, 3),\n",
        "                 activation='relu',\n",
        "                 input_shape=input_shape))\n",
        "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
        "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model.compile(loss=keras.losses.categorical_crossentropy,\n",
        "              optimizer=keras.optimizers.Adadelta(),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(x_train, y_train,\n",
        "          batch_size=batch_size,\n",
        "          epochs=epochs,\n",
        "          verbose=1,\n",
        "          validation_data=(x_valid, y_valid))\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:', score[0])\n",
        "print('Test accuracy:', score[1])\n",
        "\n",
        "preds_val = model.predict(x_valid, verbose=0)\n",
        "preds = model.predict(x_test, verbose=0)\n",
        "\n",
        "print(preds)\n",
        "\n",
        "# saving the model\n",
        "model.save(\"mnist_model.h5\")\n",
        "#print('Saved trained model at %s ' % model_path)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 1s 0us/step\n",
            "11501568/11490434 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0804 06:04:05.328114 140272604370816 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0804 06:04:05.360131 140272604370816 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0804 06:04:05.368093 140272604370816 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "W0804 06:04:05.417978 140272604370816 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0804 06:04:05.423980 140272604370816 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0804 06:04:05.435184 140272604370816 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0804 06:04:05.515968 140272604370816 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0804 06:04:05.528903 140272604370816 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0804 06:04:05.658181 140272604370816 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 51000 samples, validate on 9000 samples\n",
            "Epoch 1/12\n",
            "51000/51000 [==============================] - 131s 3ms/step - loss: 0.3092 - acc: 0.9044 - val_loss: 0.0851 - val_acc: 0.9752\n",
            "Epoch 2/12\n",
            "51000/51000 [==============================] - 129s 3ms/step - loss: 0.0964 - acc: 0.9709 - val_loss: 0.0605 - val_acc: 0.9812\n",
            "Epoch 3/12\n",
            "51000/51000 [==============================] - 129s 3ms/step - loss: 0.0700 - acc: 0.9790 - val_loss: 0.0479 - val_acc: 0.9853\n",
            "Epoch 4/12\n",
            "51000/51000 [==============================] - 129s 3ms/step - loss: 0.0581 - acc: 0.9819 - val_loss: 0.0434 - val_acc: 0.9872\n",
            "Epoch 5/12\n",
            "51000/51000 [==============================] - 130s 3ms/step - loss: 0.0485 - acc: 0.9849 - val_loss: 0.0437 - val_acc: 0.9873\n",
            "Epoch 6/12\n",
            "51000/51000 [==============================] - 130s 3ms/step - loss: 0.0442 - acc: 0.9867 - val_loss: 0.0384 - val_acc: 0.9889\n",
            "Epoch 7/12\n",
            "51000/51000 [==============================] - 130s 3ms/step - loss: 0.0384 - acc: 0.9881 - val_loss: 0.0381 - val_acc: 0.9887\n",
            "Epoch 8/12\n",
            "51000/51000 [==============================] - 130s 3ms/step - loss: 0.0341 - acc: 0.9895 - val_loss: 0.0353 - val_acc: 0.9893\n",
            "Epoch 9/12\n",
            "51000/51000 [==============================] - 131s 3ms/step - loss: 0.0314 - acc: 0.9905 - val_loss: 0.0390 - val_acc: 0.9898\n",
            "Epoch 10/12\n",
            "51000/51000 [==============================] - 131s 3ms/step - loss: 0.0296 - acc: 0.9910 - val_loss: 0.0380 - val_acc: 0.9894\n",
            "Epoch 11/12\n",
            "51000/51000 [==============================] - 131s 3ms/step - loss: 0.0259 - acc: 0.9920 - val_loss: 0.0401 - val_acc: 0.9899\n",
            "Epoch 12/12\n",
            "51000/51000 [==============================] - 131s 3ms/step - loss: 0.0247 - acc: 0.9921 - val_loss: 0.0375 - val_acc: 0.9897\n",
            "Test loss: 0.02964202083922355\n",
            "Test accuracy: 0.99\n",
            "[[1.1181856e-12 3.2378475e-13 6.8451400e-10 ... 1.0000000e+00\n",
            "  9.8698729e-13 2.8002165e-09]\n",
            " [3.7905799e-08 2.1765031e-07 9.9999976e-01 ... 2.9374315e-11\n",
            "  2.0578850e-09 3.8452162e-12]\n",
            " [1.7166109e-08 9.9999070e-01 1.3513552e-07 ... 5.7900329e-06\n",
            "  9.1913097e-07 2.2556591e-08]\n",
            " ...\n",
            " [5.6993959e-15 7.4500357e-11 1.9022525e-13 ... 3.4586481e-10\n",
            "  9.9087250e-10 7.6870798e-08]\n",
            " [7.0223992e-13 7.6681266e-12 1.6262219e-14 ... 6.4740612e-14\n",
            "  4.4924761e-07 1.4367047e-11]\n",
            " [1.8633479e-09 9.5666933e-11 1.2525755e-09 ... 1.4346522e-14\n",
            "  1.2130078e-09 2.0557727e-11]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqSDB5wC0ggC",
        "colab_type": "code",
        "outputId": "7fc738af-0130-4e02-de0c-463c8d00ebb1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "from keras.models import load_model\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Split the data\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.15, shuffle= True)\n",
        "model = load_model(\"mnist_model.h5\")\n",
        "preds_train = model.predict(x_train, verbose=0)\n",
        "preds_val = model.predict(x_valid, verbose=0)\n",
        "preds = model.predict(x_test, verbose=0)\n",
        "\n",
        "model_copy = model\n",
        "weights = model.get_weights()\n",
        "weights1 = model.get_weights()\n",
        "print(len(weights))\n",
        "#updated_weights = weights[:]\n",
        "#print(\"RESULTS\", len(updated_weights), id(weights), id(updated_weights))\n",
        "max_val = max(arr.max() for arr in weights)\n",
        "min_val = min(arr.min() for arr in weights)\n",
        "print(\"maxval is\",max_val)\n",
        "print(\"minval is\",min_val)\n",
        "\n",
        "# need to add conditions that allows arrays of different dimensions\n",
        "# Add code to check if it is an element of a list\n",
        "x = 0.0\n",
        "\n",
        "# Change fopr to while an d check it\n",
        "for r1 in range(0, len(weights)):\n",
        "  if(len(weights[r1]>1)):\n",
        "    #print(\"In r1\")\n",
        "    for r2 in range(0,len(weights[r1])):\n",
        "      #print(type(weights[r1][r2]))\n",
        "      if((type(weights[r1][r2]) is np.ndarray) and len(weights[r1][r2])>1):\n",
        "        #print(\"in r2\")\n",
        "        for r3 in range(0,len(weights[r1][r2])):\n",
        "          weights[r1][r2][r3] = (max_val-weights[r1][r2][r3])+min_val\n",
        "          #print(\"Updated\")\n",
        "      else:\n",
        "        weights[r1][r2] = (max_val-weights[r1][r2])+min_val\n",
        "        # = x\n",
        "        #print(weights1[r1][r2], weights[r1][r2])\n",
        "  else:\n",
        "    weights[r1] = (max_val-weights[r1])+min_val\n",
        "    #print(weights1[r1], weights[r1])\n",
        "   # print(\"Updated\")\n",
        "     \n",
        "model_copy.set_weights(weights)\n",
        "#model.set_weights(weights)\n",
        "print(\"W!\", len(weights1),len(weights1[1]),(weights1[1][1]))\n",
        "print(\"w\", len(weights),len(weights[1]),(weights[1][1]))\n",
        "\n",
        "\n",
        "#if(weights==weights1):\n",
        "#  print(\"Did not update\")\n",
        "\n",
        "\n",
        "copy_preds_train = model_copy.predict(x_train,verbose=0) # model to model_copy\n",
        "print(\"COPY PREDS TRAIN\")\n",
        "#print(weights)\n",
        "print(copy_preds_train[0])\n",
        "print(copy_preds_train[1])\n",
        "\n",
        "copy_preds_val = model_copy.predict(x_valid,batch_size=10, verbose=0)\n",
        "copy_preds = model_copy.predict(x_test, batch_size=10, verbose=0)\n",
        "\n",
        "#for ival in range(len(preds_val)):\n",
        "#  if(np.where(preds_val[ival] == np.amax(preds_val[ival]))!=np.where(y_valid[ival] == np.amax(y_valid[ival]))):\n",
        "#   print(np.where(preds_val[ival] == np.amax(preds_val[ival])), np.where(copy_preds_val[ival] == np.amin(copy_preds_val[ival])) , np.where(y_valid[ival] == np.amax(y_valid[ival])))\n",
        "  \n",
        "  \n",
        "match_with_copy = 0\n",
        "mismatch_with_copy = 0\n",
        "match_with_actual = 0\n",
        "mismatch_with_actual = 0\n",
        "copy_match_with_actual = 0\n",
        "copy_mismatch_with_actual = 0\n",
        "\n",
        "\n",
        "for ival in range(len(preds_val)):\n",
        "  if(np.where(preds_val[ival] == np.amax(preds_val[ival]))!=np.where(y_valid[ival] == np.amax(y_valid[ival]))):\n",
        "    mismatch_with_actual = mismatch_with_actual+1\n",
        "  else:\n",
        "    match_with_actual = match_with_actual+1\n",
        "  \n",
        "  if(np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival]))!=np.where(y_valid[ival] == np.amax(y_valid[ival]))):\n",
        "    copy_mismatch_with_actual = copy_mismatch_with_actual + 1\n",
        "  else:\n",
        "    copy_match_with_actual = copy_match_with_actual + 1\n",
        "    \n",
        "  if(np.where(preds_val[ival] == np.amax(preds_val[ival]))!=np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival]))):\n",
        "    mismatch_with_copy = mismatch_with_copy+1\n",
        "  else:\n",
        "    match_with_copy = match_with_copy+1    \n",
        "    #print(np.where(preds_val[ival] == np.amax(preds_val[ival])), np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival])), np.where(y_valid[ival] == np.amax(y_valid[ival,\n",
        "    \n",
        "print(\"Validation Results\")\n",
        "print(\"True Mode vs Actual\")\n",
        "print(\"Match = \", match_with_actual)\n",
        "print(\"Mismatch = \", mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs Actual\")\n",
        "print(\"Match = \", copy_match_with_actual)\n",
        "print(\"Mismatch = \", copy_mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs True Mode\")\n",
        "print(\"Match = \", match_with_copy)\n",
        "print(\"Mismatch = \", mismatch_with_copy)\n",
        "\n",
        "\n",
        "match_with_copy = 0\n",
        "mismatch_with_copy = 0\n",
        "match_with_actual = 0\n",
        "mismatch_with_actual = 0\n",
        "copy_match_with_actual = 0\n",
        "copy_mismatch_with_actual = 0\n",
        "\n",
        "file = open(\"globalmaxfile_mnisit_regression_input.txt\",\"w\")\n",
        "\n",
        "for ival in range(0,len(preds_train)):\n",
        "  for pval in range(0, len(preds_train[ival])):\n",
        "    file.write(str(preds_train[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  for pval in range(0,len(copy_preds_train[ival])):\n",
        "    file.write(str(copy_preds_train[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  if(np.where(preds_train[ival] == np.amax(preds_train[ival]))!=np.where(y_train[ival] == np.amax(y_train[ival]))):\n",
        "    mismatch_with_actual = mismatch_with_actual+1\n",
        "    #file.write(\" \")\n",
        "    file.write(\"0\")\n",
        "  else:\n",
        "    match_with_actual = match_with_actual+1\n",
        "    #file.write(\" \")\n",
        "    file.write(\"1\")\n",
        "  file.write(\"\\n\")\n",
        "  if(np.where(copy_preds_train[ival] == np.amax(copy_preds_train[ival]))!=np.where(y_train[ival] == np.amax(y_train[ival]))):\n",
        "    copy_mismatch_with_actual = copy_mismatch_with_actual + 1\n",
        "  else:\n",
        "    copy_match_with_actual = copy_match_with_actual + 1\n",
        "  if(np.where(preds_train[ival] == np.amax(preds_train[ival]))!=np.where(copy_preds_train[ival] == np.amax(copy_preds_train[ival]))):\n",
        "    mismatch_with_copy = mismatch_with_copy+1\n",
        "  else:\n",
        "    match_with_copy = match_with_copy+1    \n",
        "    #print(np.where(preds_val[ival] == np.amax(preds_val[ival])), np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival])), np.where(y_valid[ival] == np.amax(y_valid[ival,\n",
        "\n",
        "file.close()\n",
        "print(\"\\n\")\n",
        "print(\"Training Results\")\n",
        "print(\"True Mode vs Actual\")\n",
        "print(\"Match = \", match_with_actual)\n",
        "print(\"Mismatch = \", mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs Actual\")\n",
        "print(\"Match = \", copy_match_with_actual)\n",
        "print(\"Mismatch = \", copy_mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs True Mode\")\n",
        "print(\"Match = \", match_with_copy)\n",
        "print(\"Mismatch = \", mismatch_with_copy)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "8\n",
            "maxval is 0.36369833\n",
            "minval is -0.4463491\n",
            "W! 8 32 -0.0030425908\n",
            "w 8 32 -0.0796082\n",
            "COPY PREDS TRAIN\n",
            "[0.09430367 0.08815973 0.0943336  0.10058495 0.10458612 0.10264128\n",
            " 0.11257919 0.10360014 0.10028656 0.09892476]\n",
            "[0.09430367 0.08815973 0.0943336  0.10058495 0.10458612 0.10264128\n",
            " 0.11257919 0.10360014 0.10028656 0.09892476]\n",
            "Validation Results\n",
            "True Mode vs Actual\n",
            "Match =  8966\n",
            "Mismatch =  34\n",
            "Copy Mode vs Actual\n",
            "Match =  853\n",
            "Mismatch =  8147\n",
            "Copy Mode vs True Mode\n",
            "Match =  854\n",
            "Mismatch =  8146\n",
            "\n",
            "\n",
            "Training Results\n",
            "True Mode vs Actual\n",
            "Match =  50834\n",
            "Mismatch =  166\n",
            "Copy Mode vs Actual\n",
            "Match =  5065\n",
            "Mismatch =  45935\n",
            "Copy Mode vs True Mode\n",
            "Match =  5052\n",
            "Mismatch =  45948\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRG6VAk39vDW",
        "colab_type": "code",
        "outputId": "6e68ccc7-d842-4d5b-c740-a5ca67cfb6db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Seed value\n",
        "# Apparently you may use different seed values at each stage\n",
        "seed_value= 0\n",
        "\n",
        "# 1. Set the `PYTHONHASHSEED` environment variable at a fixed value\n",
        "import os\n",
        "os.environ['PYTHONHASHSEED']=str(seed_value)\n",
        "\n",
        "# 2. Set the `python` built-in pseudo-random generator at a fixed value\n",
        "import random\n",
        "random.seed(seed_value)\n",
        "\n",
        "# 3. Set the `numpy` pseudo-random generator at a fixed value\n",
        "import numpy as np\n",
        "np.random.seed(seed_value)\n",
        "\n",
        "# 4. Set the `tensorflow` pseudo-random generator at a fixed value\n",
        "import tensorflow as tf\n",
        "tf.set_random_seed(seed_value)\n",
        "\n",
        "from keras.models import load_model\n",
        "from __future__ import print_function\n",
        "import keras\n",
        "from keras.datasets import mnist\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras import backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "batch_size = 128\n",
        "num_classes = 10\n",
        "epochs = 12\n",
        "\n",
        "# input image dimensions\n",
        "img_rows, img_cols = 28, 28\n",
        "\n",
        "# the data, split between train and test sets\n",
        "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
        "\n",
        "if K.image_data_format() == 'channels_first':\n",
        "    x_train = x_train.reshape(x_train.shape[0], 1, img_rows, img_cols)\n",
        "    x_test = x_test.reshape(x_test.shape[0], 1, img_rows, img_cols)\n",
        "    input_shape = (1, img_rows, img_cols)\n",
        "else:\n",
        "    x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)\n",
        "    x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "    input_shape = (img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "\n",
        "# convert class vectors to binary class matrices\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\n",
        "\n",
        "\n",
        "# Split the data\n",
        "x_train, x_valid, y_train, y_valid = train_test_split(x_train, y_train, test_size=0.15, shuffle= True)\n",
        "\n",
        "model = load_model(\"mnist_model.h5\")\n",
        "preds_train = model.predict(x_train, verbose=0)\n",
        "preds_val = model.predict(x_valid, verbose=0)\n",
        "preds = model.predict(x_test, verbose=0)\n",
        "\n",
        "model_copy = model\n",
        "weights = model.get_weights()\n",
        "weights1 = model.get_weights()\n",
        "print(len(weights))\n",
        "#updated_weights = weights[:]\n",
        "#print(\"RESULTS\", len(updated_weights), id(weights), id(updated_weights))\n",
        "#max_val = max(arr.max() for arr in weights)\n",
        "#min_val = min(arr.min() for arr in weights)\n",
        "#print(\"maxval is\",max_val)\n",
        "#print(\"minval is\",min_val)\n",
        "\n",
        "# need to add conditions that allows arrays of different dimensions\n",
        "# Add code to check if it is an element of a list\n",
        "x = 0.0\n",
        "\n",
        "# Change fopr to while an d check it\n",
        "for r1 in range(0, len(weights)):\n",
        "  print(r1)\n",
        "  max_val = max(arr.max() for arr in weights[r1])\n",
        "  min_val = min(arr.min() for arr in weights[r1])\n",
        "  print(\"maxval is\",max_val)\n",
        "  print(\"minval is\",min_val)\n",
        "  if(len(weights[r1]>1)):\n",
        "    #print(\"In r1\")\n",
        "    for r2 in range(0,len(weights[r1])):\n",
        "      #print(type(weights[r1][r2]))\n",
        "      if((type(weights[r1][r2]) is np.ndarray) and len(weights[r1][r2])>1):\n",
        "        #print(\"in r2\")\n",
        "        for r3 in range(0,len(weights[r1][r2])):\n",
        "          weights[r1][r2][r3] = (max_val-weights[r1][r2][r3])+min_val\n",
        "          #print(\"Updated\")\n",
        "      else:\n",
        "        weights[r1][r2] = (max_val-weights[r1][r2])+min_val\n",
        "        # = x\n",
        "        print(weights1[r1][r2], weights[r1][r2])\n",
        "  else:\n",
        "    weights[r1] = (max_val-weights[r1])+min_val\n",
        "   # print(\"Updated\")\n",
        "     \n",
        "model_copy.set_weights(weights)\n",
        "\n",
        "print(\"W!\", len(weights1),len(weights1[1]),(weights1[1][1]))\n",
        "print(\"w\", len(weights),len(weights[1]),(weights[1][1]))\n",
        "\n",
        "\n",
        "#if(weights==weights1):\n",
        "#  print(\"Did not update\")\n",
        "\n",
        "\n",
        "copy_preds_train = model_copy.predict(x_train,verbose=0)\n",
        "print(\"SAMPLES VALUES\")\n",
        "print(copy_preds_train[1])\n",
        "print(copy_preds_train[6])\n",
        "\n",
        "copy_preds_val = model_copy.predict(x_valid, verbose=0)\n",
        "copy_preds = model_copy.predict(x_test, verbose=0)\n",
        "\n",
        "\n",
        "match_with_copy = 0\n",
        "mismatch_with_copy = 0\n",
        "match_with_actual = 0\n",
        "mismatch_with_actual = 0\n",
        "copy_match_with_actual = 0\n",
        "copy_mismatch_with_actual = 0\n",
        "\n",
        "\n",
        "file = open(\"localmaxfile_mnisit_regression_test.txt\",\"w\")\n",
        "for ival in range(len(preds)):\n",
        "  for pval in range(0, len(preds[ival])):\n",
        "    file.write(str(preds[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  for pval in range(0,len(copy_preds[ival])):\n",
        "    file.write(str(copy_preds[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  if(np.where(preds[ival] == np.amax(preds[ival]))!=np.where(y_test[ival] == np.amax(y_test[ival]))):\n",
        "    print(\"Writing zero\")\n",
        "    file.write(\"0\")\n",
        "    mismatch_with_actual = mismatch_with_actual+1\n",
        "  else:\n",
        "    file.write(\"1\")\n",
        "    match_with_actual = match_with_actual+1\n",
        "    \n",
        "  file.write(\"\\n\")\n",
        "  \n",
        "file.close()\n",
        "\n",
        "\n",
        "file = open(\"localmaxfile_mnisit_regression_input.txt\",\"w\")\n",
        "\n",
        "for ival in range(len(preds_val)):\n",
        "  for pval in range(0, len(preds_val[ival])):\n",
        "    file.write(str(preds_val[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  for pval in range(0,len(copy_preds_val[ival])):\n",
        "    file.write(str(copy_preds_val[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  if(np.where(preds_val[ival] == np.amax(preds_val[ival]))!=np.where(y_valid[ival] == np.amax(y_valid[ival]))):\n",
        "    print(\"Writing zero\")\n",
        "    file.write(\"0\")\n",
        "    mismatch_with_actual = mismatch_with_actual+1\n",
        "  else:\n",
        "    file.write(\"1\")\n",
        "    match_with_actual = match_with_actual+1\n",
        "    \n",
        "  file.write(\"\\n\")\n",
        "  \n",
        "  if(np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival]))!=np.where(y_valid[ival] == np.amax(y_valid[ival]))):\n",
        "    copy_mismatch_with_actual = copy_mismatch_with_actual + 1\n",
        "  else:\n",
        "    copy_match_with_actual = copy_match_with_actual + 1\n",
        "    \n",
        "  if(np.where(preds_val[ival] == np.amax(preds_val[ival]))!=np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival]))):\n",
        "    mismatch_with_copy = mismatch_with_copy+1\n",
        "  else:\n",
        "    match_with_copy = match_with_copy+1    \n",
        "    #print(np.where(preds_val[ival] == np.amax(preds_val[ival])), np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival])), np.where(y_valid[ival] == np.amax(y_valid[ival,\n",
        "    \n",
        "print(\"Results\")\n",
        "print(\"True Mode vs Actual\")\n",
        "print(\"Match = \", match_with_actual)\n",
        "print(\"Mismatch = \", mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs Actual\")\n",
        "print(\"Match = \", copy_match_with_actual)\n",
        "print(\"Mismatch = \", copy_mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs True Mode\")\n",
        "print(\"Match = \", match_with_copy)\n",
        "print(\"Mismatch = \", mismatch_with_copy)\n",
        "\n",
        "\n",
        "match_with_copy = 0\n",
        "mismatch_with_copy = 0\n",
        "match_with_actual = 0\n",
        "mismatch_with_actual = 0\n",
        "copy_match_with_actual = 0\n",
        "copy_mismatch_with_actual = 0\n",
        "\n",
        "\n",
        "\n",
        "for ival in range(0,len(preds_train)):\n",
        "  for pval in range(0, len(preds_train[ival])):\n",
        "    file.write(str(preds_train[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  for pval in range(0,len(copy_preds_train[ival])):\n",
        "    file.write(str(copy_preds_train[ival][pval]))\n",
        "    file.write(\" \")\n",
        "  if(np.where(preds_train[ival] == np.amax(preds_train[ival]))!=np.where(y_train[ival] == np.amax(y_train[ival]))):\n",
        "    file.write(\"0\")\n",
        "    mismatch_with_actual = mismatch_with_actual+1\n",
        "  else:\n",
        "    file.write(\"1\")\n",
        "    match_with_actual = match_with_actual+1\n",
        "   \n",
        "  file.write(\"\\n\")\n",
        "  if(np.where(copy_preds_train[ival] == np.amax(copy_preds_train[ival]))!=np.where(y_train[ival] == np.amax(y_train[ival]))):\n",
        "    copy_mismatch_with_actual = copy_mismatch_with_actual + 1\n",
        "  else:\n",
        "    copy_match_with_actual = copy_match_with_actual + 1\n",
        "  if(np.where(preds_train[ival] == np.amax(preds_train[ival]))!=np.where(copy_preds_train[ival] == np.amax(copy_preds_train[ival]))):\n",
        "    mismatch_with_copy = mismatch_with_copy+1\n",
        "  else:\n",
        "    match_with_copy = match_with_copy+1    \n",
        "    #print(np.where(preds_val[ival] == np.amax(preds_val[ival])), np.where(copy_preds_val[ival] == np.amax(copy_preds_val[ival])), np.where(y_valid[ival] == np.amax(y_valid[ival,\n",
        "\n",
        "print(\"\\n\")\n",
        "print(\"Training Results\")\n",
        "print(\"True Mode vs Actual\")\n",
        "print(\"Match = \", match_with_actual)\n",
        "print(\"Mismatch = \", mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs Actual\")\n",
        "print(\"Match = \", copy_match_with_actual)\n",
        "print(\"Mismatch = \", copy_mismatch_with_actual)\n",
        "\n",
        "print(\"Copy Mode vs True Mode\")\n",
        "print(\"Match = \", match_with_copy)\n",
        "print(\"Mismatch = \", mismatch_with_copy)\n",
        "\n"
      ],
      "execution_count": 124,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "W0805 22:13:16.880948 140120563128192 deprecation_wrapper.py:119] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "W0805 22:13:16.892723 140120563128192 deprecation.py:506] From /usr/local/lib/python2.7/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0805 22:13:24.296336 140120563128192 deprecation.py:323] From /usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/math_grad.py:1250: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "8\n",
            "0\n",
            "maxval is 0.3770912\n",
            "minval is -0.451004\n",
            "1\n",
            "maxval is 0.1364974\n",
            "minval is -0.034754965\n",
            "0.1364974 -0.034754965\n",
            "0.025890594 0.07585183\n",
            "-0.034754965 0.1364974\n",
            "-0.006958223 0.10870065\n",
            "0.041041296 0.060701128\n",
            "-0.002422107 0.10416454\n",
            "-0.017479245 0.11922167\n",
            "0.051986013 0.04975642\n",
            "0.06629018 0.03545225\n",
            "0.089413 0.012329426\n",
            "-0.033373173 0.13511561\n",
            "-0.011621753 0.11336419\n",
            "0.0 0.10174243\n",
            "0.07486911 0.026873317\n",
            "-0.005242078 0.10698451\n",
            "0.06555217 0.03619026\n",
            "-0.00065696845 0.102399394\n",
            "0.008279745 0.09346269\n",
            "0.025940605 0.07580182\n",
            "0.07765344 0.02408899\n",
            "-0.009526756 0.11126919\n",
            "0.015033784 0.08670865\n",
            "0.00061017065 0.10113226\n",
            "-0.010968002 0.11271043\n",
            "-0.015430337 0.11717276\n",
            "0.012489267 0.08925316\n",
            "0.047010086 0.05473234\n",
            "0.04159743 0.060145\n",
            "-0.013145431 0.11488786\n",
            "-0.033625297 0.13536772\n",
            "0.06726579 0.034476634\n",
            "0.030432867 0.07130957\n",
            "2\n",
            "maxval is 0.25972104\n",
            "minval is -0.29104987\n",
            "3\n",
            "maxval is 0.08349224\n",
            "minval is -0.053740002\n",
            "-0.023485057 0.053237297\n",
            "-0.0024213092 0.03217355\n",
            "-0.04808879 0.077841036\n",
            "0.009309013 0.020443223\n",
            "0.011968809 0.017783433\n",
            "-0.02811787 0.057870112\n",
            "-0.0033516502 0.03310389\n",
            "-0.04490722 0.07465946\n",
            "0.00925913 0.020493113\n",
            "-0.0020072255 0.031759463\n",
            "0.015500563 0.014251679\n",
            "-0.0012230037 0.030975245\n",
            "-0.0072253337 0.036977574\n",
            "-0.023164855 0.052917093\n",
            "-0.007871416 0.03762366\n",
            "-0.042881157 0.07263339\n",
            "0.06329236 -0.033540122\n",
            "0.013649866 0.016102374\n",
            "-0.023483686 0.053235926\n",
            "0.018874869 0.010877371\n",
            "0.035577282 -0.0058250427\n",
            "-0.016916288 0.04666853\n",
            "0.012756551 0.01699569\n",
            "-0.021633107 0.05138535\n",
            "-0.053740002 0.08349224\n",
            "0.018610805 0.011141434\n",
            "-0.04513432 0.07488655\n",
            "-0.0032691332 0.033021376\n",
            "0.08349224 -0.053740002\n",
            "-0.019154705 0.048906945\n",
            "0.009399334 0.020352907\n",
            "-0.0010605921 0.03081283\n",
            "-0.0018576535 0.031609893\n",
            "0.027897513 0.0018547252\n",
            "-0.028605884 0.058358125\n",
            "-0.021014035 0.050766274\n",
            "-0.017043196 0.046795435\n",
            "-0.029097438 0.058849677\n",
            "-0.022926806 0.052679047\n",
            "0.009775586 0.019976653\n",
            "-0.0008531399 0.030605383\n",
            "-0.011154774 0.04090701\n",
            "0.018033115 0.0117191225\n",
            "-0.014994777 0.044747017\n",
            "-0.01906477 0.04881701\n",
            "-0.0100290915 0.039781332\n",
            "-0.036789585 0.06654183\n",
            "-0.03932333 0.06907557\n",
            "-0.0076229316 0.037375174\n",
            "0.021855485 0.007896755\n",
            "0.025448041 0.0043042004\n",
            "-0.04288147 0.072633706\n",
            "0.013417752 0.016334489\n",
            "0.067999735 -0.038247496\n",
            "0.006583895 0.023168348\n",
            "-0.014810253 0.044562496\n",
            "-0.0069749607 0.036727197\n",
            "-0.03182536 0.061577596\n",
            "-0.026633764 0.056386\n",
            "-0.0022452688 0.03199751\n",
            "-0.03686112 0.06661336\n",
            "-0.016010478 0.045762718\n",
            "-0.0043883068 0.03414055\n",
            "-0.024012174 0.05376441\n",
            "4\n",
            "maxval is 0.1387204\n",
            "minval is -0.12920329\n",
            "5\n",
            "maxval is 0.031676\n",
            "minval is -0.13135691\n",
            "-0.053688608 -0.0459923\n",
            "-0.059628535 -0.04005237\n",
            "-0.013792038 -0.08588887\n",
            "-0.07666531 -0.023015596\n",
            "-0.05620189 -0.043479018\n",
            "-0.06500093 -0.03467998\n",
            "-0.05580473 -0.04387618\n",
            "-0.037780758 -0.061900154\n",
            "-0.047300454 -0.052380458\n",
            "-0.012407951 -0.08727296\n",
            "-0.014166135 -0.08551477\n",
            "0.0027104223 -0.10239133\n",
            "0.012904853 -0.11258576\n",
            "-0.01867387 -0.08100703\n",
            "-0.0384387 -0.061242208\n",
            "-0.04473646 -0.05494445\n",
            "-0.03915717 -0.060523733\n",
            "0.006328734 -0.10600964\n",
            "-0.040581085 -0.059099823\n",
            "-0.06664096 -0.03303995\n",
            "0.003393434 -0.10307434\n",
            "-0.021920567 -0.07776034\n",
            "-0.08231143 -0.017369479\n",
            "-0.0527201 -0.04696081\n",
            "0.008256877 -0.10793778\n",
            "-0.035173588 -0.06450732\n",
            "-0.030900182 -0.06878073\n",
            "-0.04085799 -0.058822915\n",
            "-0.08190946 -0.017771445\n",
            "-0.05855926 -0.041121647\n",
            "-0.052904382 -0.046776526\n",
            "0.031676 -0.13135691\n",
            "-0.03290945 -0.06677146\n",
            "-0.016842086 -0.08283882\n",
            "-0.024461806 -0.0752191\n",
            "-0.041091975 -0.058588937\n",
            "-0.07542656 -0.024254344\n",
            "-0.011679458 -0.088001445\n",
            "-0.102838926 0.003158018\n",
            "-0.06430699 -0.03537392\n",
            "-0.07810749 -0.021573417\n",
            "-0.04250502 -0.05717589\n",
            "-0.09192959 -0.007751316\n",
            "-0.060295526 -0.03938538\n",
            "-0.077992156 -0.021688752\n",
            "0.011887213 -0.11156812\n",
            "-0.03224447 -0.06743644\n",
            "-0.020543264 -0.079137646\n",
            "-0.07820333 -0.02147758\n",
            "-0.064279206 -0.035401702\n",
            "-0.03622821 -0.0634527\n",
            "-0.0577665 -0.041914403\n",
            "-0.021044636 -0.078636274\n",
            "-0.07253138 -0.027149528\n",
            "-0.012534222 -0.087146685\n",
            "-0.03406516 -0.06561574\n",
            "-0.07133979 -0.028341115\n",
            "-0.07329651 -0.026384398\n",
            "-0.07199314 -0.027687766\n",
            "0.025251321 -0.12493223\n",
            "-0.13135691 0.03167601\n",
            "-0.04135715 -0.058323756\n",
            "-0.009790519 -0.08989039\n",
            "-0.0006290708 -0.09905183\n",
            "-0.0349601 -0.06472081\n",
            "-0.0058601843 -0.09382072\n",
            "-0.08021317 -0.019467741\n",
            "-0.030161275 -0.06951963\n",
            "-0.046410587 -0.053270325\n",
            "-0.06367673 -0.03600418\n",
            "-0.08688227 -0.012798637\n",
            "-0.03189723 -0.06778368\n",
            "-0.07911012 -0.020570785\n",
            "-0.053504776 -0.046176136\n",
            "-0.007207826 -0.09247308\n",
            "-0.0314011 -0.0682798\n",
            "-0.04971952 -0.049961388\n",
            "-0.03563457 -0.06404634\n",
            "-0.058848854 -0.040832058\n",
            "-0.011555525 -0.088125385\n",
            "-0.044475153 -0.055205755\n",
            "-0.020429486 -0.07925142\n",
            "0.0040707504 -0.10375166\n",
            "-0.0213667 -0.07831421\n",
            "-0.028182711 -0.0714982\n",
            "-0.020671448 -0.07900946\n",
            "-0.0008595511 -0.09882136\n",
            "-0.07232645 -0.027354456\n",
            "-0.052216567 -0.04746434\n",
            "-0.086420365 -0.013260543\n",
            "-0.032195363 -0.06748554\n",
            "-0.08724147 -0.012439437\n",
            "-0.057036046 -0.04264486\n",
            "-0.0043361615 -0.095344745\n",
            "-0.06352953 -0.03615138\n",
            "-0.040036473 -0.05964443\n",
            "-0.039013762 -0.060667142\n",
            "0.0002447475 -0.09992565\n",
            "0.00013048988 -0.0998114\n",
            "-0.06430425 -0.03537666\n",
            "-0.046337124 -0.053343788\n",
            "-0.03769279 -0.061988115\n",
            "-0.01972646 -0.079954445\n",
            "-0.03992654 -0.05975437\n",
            "-0.031317845 -0.06836306\n",
            "-0.014670674 -0.08501023\n",
            "0.0033472066 -0.10302812\n",
            "0.0012346705 -0.10091558\n",
            "-0.018807031 -0.08087388\n",
            "-0.06736969 -0.032311216\n",
            "-0.043814223 -0.05586669\n",
            "-0.017257694 -0.08242321\n",
            "-0.034398723 -0.06528218\n",
            "-0.079051375 -0.020629533\n",
            "-0.035027586 -0.06465332\n",
            "-0.054192085 -0.04548882\n",
            "-0.01010585 -0.08957506\n",
            "-0.011032477 -0.08864843\n",
            "-0.12892199 0.02924107\n",
            "-0.049891964 -0.049788944\n",
            "-0.03572622 -0.06395469\n",
            "-0.021932263 -0.07774864\n",
            "-0.04313497 -0.056545943\n",
            "-0.011645786 -0.08803512\n",
            "-0.08093444 -0.018746465\n",
            "-0.024568064 -0.07511284\n",
            "-0.094001815 -0.005679086\n",
            "-0.02078783 -0.07889308\n",
            "6\n",
            "maxval is 0.31839663\n",
            "minval is -0.46247837\n",
            "7\n",
            "maxval is 0.07647189\n",
            "minval is -0.11763192\n",
            "-0.03911562 -0.002044417\n",
            "0.07647189 -0.11763192\n",
            "-0.06872378 0.027563743\n",
            "0.062276132 -0.103436165\n",
            "-0.0146160405 -0.02654399\n",
            "0.0014918662 -0.0426519\n",
            "-0.11763192 0.07647189\n",
            "-0.06477402 0.023613982\n",
            "-0.0016655322 -0.0394945\n",
            "0.04316697 -0.084327\n",
            "W! 8 32 0.025890594\n",
            "w 8 32 0.07585183\n",
            "SAMPLES VALUES\n",
            "[3.2371270e-09 2.1649761e-05 1.6903410e-06 9.0760204e-07 1.1734541e-06\n",
            " 4.5531569e-06 9.9996996e-01 3.0532174e-08 1.2315654e-09 9.3572599e-09]\n",
            "[1.1623857e-05 1.6871692e-05 3.7044080e-07 3.7368459e-11 9.8062700e-01\n",
            " 1.8713645e-11 1.9300476e-02 4.2853411e-05 3.6531848e-08 7.5910128e-07]\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Writing zero\n",
            "Results\n",
            "True Mode vs Actual\n",
            "Match =  18881\n",
            "Mismatch =  119\n",
            "Copy Mode vs Actual\n",
            "Match =  4070\n",
            "Mismatch =  4930\n",
            "Copy Mode vs True Mode\n",
            "Match =  4073\n",
            "Mismatch =  4927\n",
            "\n",
            "\n",
            "Training Results\n",
            "True Mode vs Actual\n",
            "Match =  50813\n",
            "Mismatch =  187\n",
            "Copy Mode vs Actual\n",
            "Match =  23054\n",
            "Mismatch =  27946\n",
            "Copy Mode vs True Mode\n",
            "Match =  23093\n",
            "Mismatch =  27907\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lz_KcBfIArWY",
        "colab_type": "code",
        "outputId": "2daac986-cb45-4049-e808-d613dd6cf4a7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Linear regression with scikit\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "from sklearn import metrics\n",
        "from sklearn import svm\n",
        "\n",
        "rfile = open(\"localmaxfile_mnisit_regression_input.txt\",\"r\")\n",
        "\n",
        "f1 = rfile.readlines()\n",
        "\n",
        "Xdata = []\n",
        "Ydata = []\n",
        "iterval = 0\n",
        "for li in f1:\n",
        "  li = li.replace(\"\\n\",\"\")\n",
        "  values = li.split(\" \")\n",
        "  x_val = values[0:len(values)-1]\n",
        "  x_val = [float(i) for i in x_val] \n",
        "  y_val = float(values[len(values)-1])\n",
        "  if y_val == 0:\n",
        "      y_val = [1, 0]\n",
        "  else:\n",
        "      y_val = [0, 1]\n",
        "  #print(x_val,y_val)\n",
        "  Xdata.insert(iterval,x_val)\n",
        "  Ydata.insert(iterval,y_val)\n",
        "  iterval = iterval+1\n",
        "  \n",
        "rfile.close()\n",
        "print(Xdata[0])\n",
        "print(Ydata[0])\n",
        "\n",
        "\n",
        "Xdatar = np.asarray(Xdata, dtype=np.float32)\n",
        "Ydatar = np.asarray(Ydata, dtype=np.float32)\n",
        "print(Xdatar.shape)\n",
        "\n",
        "Xdatar = np.reshape(Xdatar,(60000,1,20))\n",
        "Ydatar = np.reshape(Ydatar,(60000,1,2))\n",
        "\n",
        "\n",
        "tstfile = open(\"localmaxfile_mnisit_regression_test.txt\",\"r\")\n",
        "\n",
        "f2 = tstfile.readlines()\n",
        "\n",
        "Xtstdata = []\n",
        "Ytstdata = []\n",
        "iterval = 0\n",
        "for li in f2:\n",
        "  li = li.replace(\"\\n\",\"\")\n",
        "  values = li.split(\" \")\n",
        "  x_val = values[0:len(values)-1]\n",
        "  x_val = [float(i) for i in x_val] \n",
        "  y_val = float(values[len(values)-1])\n",
        "  if y_val == 0:\n",
        "      y_val = [1, 0]\n",
        "  else:\n",
        "      y_val = [0, 1]\n",
        "  Xtstdata.insert(iterval,x_val)\n",
        "  Ytstdata.insert(iterval,y_val)\n",
        "  iterval = iterval+1\n",
        "\n",
        "tstfile.close()\n",
        "print(Xtstdata[0])\n",
        "print(Ytstdata[0])\n",
        "\n",
        "\n",
        "Xtstdatar = np.asarray(Xtstdata, dtype=np.float32)\n",
        "Ytstdatar = np.asarray(Ytstdata, dtype=np.float32)\n",
        "print(Xdatar.shape)\n",
        "\n",
        "Xtstdatar = np.reshape(Xtstdatar,(len(Xtstdatar),1,20))\n",
        "Ytstdatar = np.reshape(Ytstdatar,(len(Xtstdatar),1,2))\n",
        "\n",
        "#X_trainr1, X_testr1, y_trainr1, y_testr1 = train_test_split(Xdata, Ydata, random_state=1)\n",
        "\n",
        "X_trainr, X_testr, y_trainr, y_testr = train_test_split(Xdatar, Ydatar, random_state=1)\n",
        "\n",
        "#Converting into categorical attributes\n",
        "#num_classes = 2 \n",
        "#y_trainr = keras.utils.to_categorical(y_trainr, num_classes)\n",
        "#y_testr = keras.utils.to_categorical(y_testr, num_classes)\n",
        "\n",
        "\n",
        "# instantiate\n",
        "#linreg = LinearRegression()\n",
        "\n",
        "# fit the model to the training data (learn the coefficients)\n",
        "#linreg.fit(X_trainr1, y_trainr1)\n",
        "\n",
        "#clf_no_weights = svm.SVC(gamma=1)\n",
        "#clf_no_weights.fit(X_trainr1, y_trainr1)\n",
        "\n",
        "#y_predsvm = clf_no_weights.predict(X_trainr1)\n",
        "\n",
        "\n",
        "#y_predr = linreg.predict(X_trainr1)\n",
        "\n",
        "#for rval in range(0, len(y_predr)):\n",
        "#  if(y_trainr1[rval]==0):\n",
        "#    print(y_trainr1[rval],y_predsvm[rval], y_predr[rval])\n",
        "    \n",
        "#print(np.sqrt(metrics.mean_squared_error(y_trainr1, y_predsvm)))\n",
        "\n",
        "\n",
        "#print(X_trainr[1])\n",
        "\n",
        "new_model = Sequential()\n",
        "new_model.add(Dense(64, input_shape=(1,20), activation='relu'))\n",
        "new_model.add(Dense(32,  activation='relu'))\n",
        "new_model.add(Dense(16,  activation='relu'))\n",
        "new_model.add(Dense(10,  activation='relu'))\n",
        "new_model.add(Dense(5,  activation='relu'))\n",
        "#new_model.add(Dense(3, activation='relu'))\n",
        "new_model.add(Dense(2))\n",
        "\t# Compile model\n",
        "new_model.compile(loss='mean_squared_error', metrics={'output_a': 'accuracy'}, optimizer='adam')\n",
        "\n",
        "\n",
        "#SUCESSFUL MODEL\n",
        "#new_model = Sequential()\n",
        "#new_model.add(Dense(32, input_shape=(1,20), activation='relu'))\n",
        "#new_model.add(Dense(16,  activation='relu'))\n",
        "#new_model.add(Dense(8,  activation='relu'))\n",
        "#new_model.add(Dense(5,  activation='relu'))\n",
        "#new_model.add(Dense(2))\n",
        "\t# Compile model\n",
        "new_model.compile(loss='mean_squared_error', metrics={'output_a': 'accuracy'}, optimizer='adam')\n",
        "\n",
        "\n",
        "class_weights = {0: 1.,\n",
        "                1: 99.}\n",
        "\n",
        "new_model.summary()\n",
        "new_model.fit(Xdatar, Ydatar,\n",
        "          batch_size=32,\n",
        "          epochs=12,\n",
        "          validation_split = 0.15)\n",
        "          #verbose=1,\n",
        "          #validation_data=(x_valid, y_valid))\n",
        "score = new_model.evaluate(Xtstdatar, Ytstdatar, verbose=0)\n",
        "print(score)\n",
        "\n",
        "match = 0.0\n",
        "mismatch = 0.0\n",
        "acc = 0.0\n",
        "actual_acc = 0.0\n",
        "mismatch_acc = 0.0\n",
        "actual_count = 0.0\n",
        "preds_testr = new_model.predict(Xtstdatar)\n",
        "for rval in range(0, len(preds_testr)):\n",
        "  x = np.where(Ytstdatar[rval][0] == np.amax(Ytstdatar[rval][0])), \n",
        "  y = np.where(preds_testr[rval][0] == np.amax(preds_testr[rval][0]))\n",
        "  #print(x,y)\n",
        "  if(x[0][0]==1):\n",
        "    actual_count = actual_count+1\n",
        "  if(x==y):\n",
        "    match = match + 1\n",
        "    if(x[0][0]==0):\n",
        "      print(rval)\n",
        "  else:\n",
        "    mismatch = mismatch + 1\n",
        "    if(x[0][0]==1):\n",
        "      print(\"1 -- \",rval)\n",
        "    \n",
        "acc = match/len(preds_testr)\n",
        "actual_acc = actual_count/len(preds_testr)\n",
        "\n",
        "print(\"Match = \",match)\n",
        "print(\"Acc = \",acc)\n",
        "print(\"Actual acc =\",actual_acc)\n",
        "  \n",
        "#max_testr = 0.0\n",
        "#min_testr = 2.0\n",
        "#count = 0\n",
        "#total_count = 0.0\n",
        "#match_count = 0.0\n",
        "#mismatch_count = 0.0\n",
        "#one_count = 0.0\n",
        "#for rval in range(0, len(preds_testr)):\n",
        "#  if(y_testr[rval]==0 and preds_testr[rval][0]<0.875):\n",
        "#    match_count = match_count + 1\n",
        "#  elif(y_testr[rval]==1 and preds_testr[rval][0]>=0.875):\n",
        "#    match_count = match_count + 1\n",
        "#  else:\n",
        "#    mismatch_count = mismatch_count + 1\n",
        "    #print(np.where(y_testr[rval][0] == np.amax(y_testr[rval][0])), np.where(preds_testr[rval][0] == np.amax(preds_testr[rval][0])))\n",
        "    #print(y_testr[rval], preds_testr[rval])\n",
        "#  if(preds_testr[rval][0]>max_testr):\n",
        "#     max_testr = preds_testr[rval][0]\n",
        "#  if(preds_testr[rval][0]<min_testr):\n",
        "#     min_testr = preds_testr[rval][0]\n",
        "#  if(preds_testr[rval][0]>0.85):\n",
        "#     count = count+ 1\n",
        "#  if(y_testr[rval]==1):\n",
        "#    one_count = one_count+1\n",
        "\n",
        "#print(\"total Count is \",len(preds_testr))\n",
        "#print(\"Match count = \", match_count)\n",
        "#print(\"Mismatch count = \",mismatch_count)\n",
        "#print(\"Actual match count = \",one_count)\n",
        "#acc = match_count/len(preds_testr)\n",
        "#mismatch_acc = mismatch_count/len(preds_testr)\n",
        "#actual_acc = one_count/len(preds_testr)\n",
        "\n",
        "#print(\"Accuracy \", acc)\n",
        "#print(\"MISMATC ACC\", mismatch_acc)\n",
        "#print(\"Actual acc\",actual_acc)\n",
        "#print(\"MAX VAL IS\",max_testr)\n",
        "#print(\"MIN VAL IS\",min_testr)\n",
        "\n",
        "#print('Test loss:', score[0])\n",
        "#print('Test accuracy:', score[1])"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[8.2118165e-18, 2.2608228e-12, 1.1016679e-10, 1.0, 6.4696546e-15, 4.2823084e-12, 8.427038e-18, 3.5969172e-11, 2.4449439e-11, 1.6706112e-11, 1.1012843e-09, 0.46677437, 1.3723873e-07, 0.52846384, 0.00018124007, 0.0002094329, 0.0006534478, 0.00313675, 3.5069593e-08, 0.00058065006]\n",
            "[0, 1]\n",
            "(60000, 20)\n",
            "[1.5637824e-11, 1.7296886e-11, 7.82187e-10, 1.5400412e-10, 5.8081754e-14, 1.9258327e-13, 5.9527317e-18, 1.0, 3.455002e-14, 8.8799516e-11, 9.864562e-11, 3.1622207e-07, 3.3201216e-11, 1.479166e-07, 1.2357351e-05, 1.9504357e-12, 9.003917e-10, 0.9999871, 9.129973e-13, 3.1440996e-11]\n",
            "[0, 1]\n",
            "(60000, 1, 20)\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_177 (Dense)            (None, 1, 64)             1344      \n",
            "_________________________________________________________________\n",
            "dense_178 (Dense)            (None, 1, 32)             2080      \n",
            "_________________________________________________________________\n",
            "dense_179 (Dense)            (None, 1, 16)             528       \n",
            "_________________________________________________________________\n",
            "dense_180 (Dense)            (None, 1, 10)             170       \n",
            "_________________________________________________________________\n",
            "dense_181 (Dense)            (None, 1, 5)              55        \n",
            "_________________________________________________________________\n",
            "dense_182 (Dense)            (None, 1, 2)              12        \n",
            "=================================================================\n",
            "Total params: 4,189\n",
            "Trainable params: 4,189\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Train on 51000 samples, validate on 9000 samples\n",
            "Epoch 1/12\n",
            "51000/51000 [==============================] - 10s 187us/step - loss: 0.0208 - val_loss: 0.0034\n",
            "Epoch 2/12\n",
            "51000/51000 [==============================] - 5s 89us/step - loss: 0.0035 - val_loss: 0.0033\n",
            "Epoch 3/12\n",
            "51000/51000 [==============================] - 5s 89us/step - loss: 0.0034 - val_loss: 0.0032\n",
            "Epoch 4/12\n",
            "51000/51000 [==============================] - 5s 92us/step - loss: 0.0034 - val_loss: 0.0032\n",
            "Epoch 5/12\n",
            "51000/51000 [==============================] - 5s 91us/step - loss: 0.0032 - val_loss: 0.0029\n",
            "Epoch 6/12\n",
            "51000/51000 [==============================] - 5s 92us/step - loss: 0.0029 - val_loss: 0.0025\n",
            "Epoch 7/12\n",
            "51000/51000 [==============================] - 5s 89us/step - loss: 0.0027 - val_loss: 0.0025\n",
            "Epoch 8/12\n",
            "51000/51000 [==============================] - 5s 90us/step - loss: 0.0027 - val_loss: 0.0026\n",
            "Epoch 9/12\n",
            "51000/51000 [==============================] - 5s 90us/step - loss: 0.0026 - val_loss: 0.0026\n",
            "Epoch 10/12\n",
            "51000/51000 [==============================] - 5s 91us/step - loss: 0.0025 - val_loss: 0.0027\n",
            "Epoch 11/12\n",
            "51000/51000 [==============================] - 5s 90us/step - loss: 0.0025 - val_loss: 0.0025\n",
            "Epoch 12/12\n",
            "51000/51000 [==============================] - 5s 91us/step - loss: 0.0024 - val_loss: 0.0025\n",
            "0.007720206844439963\n",
            "1202\n",
            "1232\n",
            "('1 -- ', 1242)\n",
            "('1 -- ', 1621)\n",
            "2293\n",
            "2387\n",
            "('1 -- ', 2406)\n",
            "2414\n",
            "2921\n",
            "2927\n",
            "3597\n",
            "4075\n",
            "('1 -- ', 4571)\n",
            "6560\n",
            "('1 -- ', 6576)\n",
            "('1 -- ', 8246)\n",
            "8408\n",
            "8527\n",
            "('Match = ', 9915.0)\n",
            "('Acc = ', 0.9915)\n",
            "('Actual acc =', 0.9909)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}